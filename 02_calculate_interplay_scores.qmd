---
title: "Calculate Interplay Scores"
date: 02/13/2024
date-format: YYYY-MM-DD
author: Karl F Poncha
output: html
execute:
  echo: false
---

```{python find and match PTMs from combos1 to combos2 then calculate I, ACI, NI}
import os
import re
import numpy as np
import pandas as pd

# Function to find matching file pairs
def find_matching_files(combos_1_dir, combos_2_dir):
    combos_1_files = {f.replace('_combos_1.csv', ''): os.path.join(combos_1_dir, f) 
                      for f in os.listdir(combos_1_dir) if f.endswith('_combos_1.csv')}
    combos_2_files = {f.replace('_combos_2.csv', ''): os.path.join(combos_2_dir, f) 
                      for f in os.listdir(combos_2_dir) if f.endswith('_combos_2.csv')}

    matched_files = [(combos_1_files[k], combos_2_files[k]) 
                     for k in combos_1_files if k in combos_2_files]
    return matched_files

# Interplay calculation function, adjusted for the actual column names and numpy usage
def process_combo_pair(combos_1_file, combos_2_file, output_dir):
    # Load combo files
    df_combos_1 = pd.read_csv(combos_1_file)
    df_combos_2 = pd.read_csv(combos_2_file)

    # Rename columns based on the actual file structure
    df_combos_1.rename(columns={'PTM Combination': 'discrete_mod', 'Percentage Abundance': 'discrete_abundance'}, inplace=True)
    df_combos_2.rename(columns={'PTM Combination': 'binary_comb', 'Percentage Abundance': 'binary_abundance'}, inplace=True)

    # Split PTM combinations in combos_2
    df_combos_2[['PTM_1', 'PTM_2']] = df_combos_2['binary_comb'].apply(
        lambda x: pd.Series(re.findall(r'([A-Z]\d*[^A-Z]*)', x)[:2])
    )

    # Merge to get abundances for each PTM in the combinations
    df_combos_2 = df_combos_2.merge(df_combos_1, left_on='PTM_1', right_on='discrete_mod', how='left')\
                             .rename(columns={'discrete_abundance': 'discrete_abundance_1'})
    df_combos_2 = df_combos_2.merge(df_combos_1, left_on='PTM_2', right_on='discrete_mod', how='left')\
                             .rename(columns={'discrete_abundance': 'discrete_abundance_2'})

    # Calculate interplay score using numpy for the natural log function
    df_combos_2['interplay'] = np.log(df_combos_2['binary_abundance'] / 
                                      (df_combos_2['discrete_abundance_1'] * df_combos_2['discrete_abundance_2']))
    
    # Calculate abundance-corrected interplay score
    df_combos_2['abundance_corrected_interplay'] = np.log(
      (df_combos_2['binary_abundance'] *
       (1 - df_combos_2['discrete_abundance_1']) *
       (1 - df_combos_2['discrete_abundance_2'])) /
      (df_combos_2['discrete_abundance_1'] *
       df_combos_2['discrete_abundance_2'] *
       (df_combos_2['discrete_abundance_1'] - df_combos_2['binary_abundance']) *
       (df_combos_2['discrete_abundance_2'] - df_combos_2['binary_abundance']))
    )
      
    # Calculate normalized interplay
    df_combos_2['normalized_interplay'] = df_combos_2['interplay'] / (-np.log(df_combos_2['binary_abundance']))

    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Construct the output file path and save the processed DataFrame
    output_file = os.path.basename(combos_2_file).replace('_combos_2.csv', '_interplay_scores.csv')
    output_file_path = os.path.join(output_dir, output_file)
    df_combos_2.to_csv(output_file_path, index=False)
    print(f'Saved processed data to: {output_file_path}')

# Paths are set as per the current working directory and the specified structure
base_dir = os.path.join(os.getcwd())  # Using the current working directory as base
combos_1_dir = os.path.join(base_dir, 'output', 'combos', 'combos_1')
combos_2_dir = os.path.join(base_dir, 'output', 'combos', 'combos_2')
output_dir = os.path.join(base_dir, 'output', 'interplay_scores')  # Output directory for interplay scores

# Find matching files and process each pair
matched_files = find_matching_files(combos_1_dir, combos_2_dir)
for combos_1_file, combos_2_file in matched_files:
    process_combo_pair(combos_1_file, combos_2_file, output_dir)

```

```{python process files to calculate averages of interplay scores}
import os
import pandas as pd
import re

def parse_ptms(proteoform):
    # Find all post-translational modifications (PTMs) in the proteoform string
    ptms = re.findall(r'([A-Z]\d*[^A-Z]*)', proteoform)
    return ptms[:2]  # Return only the first two PTMs found

def process_files(annotation_df, base_dir, input_dir, output_dir):
    # Construct full input and output paths
    input_path = os.path.join(base_dir, input_dir)
    output_path = os.path.join(base_dir, output_dir)

    # Ensure output directory exists
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # Dictionary to store dataframes for each condition and histone for processing
    condition_histone_dfs = {}

    # Loop through each file and process
    for index, row in annotation_df.iterrows():
        file_name = row['filename']
        file_path = os.path.join(input_path, file_name)
        condition = row['condition']
        sample_name = row['sample_name']
        biorep = row['biorep']
        histone = row['histone']
        unique_suffix = f"{sample_name}_rep{biorep}_{histone}"

        # Load the CSV file
        try:
            data_df = pd.read_csv(file_path)

            # Pre-rename all columns to include unique suffix, except 'binary_comb'
            rename_columns = {col: f'{col}_{unique_suffix}' for col in data_df.columns if col != 'binary_comb'}
            data_df.rename(columns=rename_columns, inplace=True)

            # Merge dataframes based on 'binary_comb', condition, and histone
            key = (condition, histone)
            if key in condition_histone_dfs:
                condition_histone_dfs[key] = pd.merge(condition_histone_dfs[key], data_df, on='binary_comb', how='outer')
            else:
                condition_histone_dfs[key] = data_df

        except FileNotFoundError:
            print(f"File not found: {file_path}")
            continue

    # Process each dataframe to fill NAs and calculate averages
    for (condition, histone), df in condition_histone_dfs.items():
        df.fillna(0, inplace=True)
        
        interplay_columns = df.filter(regex='interplay_').columns
        df['avg_interplay'] = df[interplay_columns].mean(axis=1)
        
        ac_interplay_columns = df.filter(regex='abundance_corrected_interplay_').columns
        df['avg_abundance_corrected_interplay'] = df[ac_interplay_columns].mean(axis=1)
        
        normalized_columns = df.filter(regex='normalized_interplay_').columns
        df['avg_normalized_interplay'] = df[normalized_columns].mean(axis=1)

        # Parse PTMs and add as new columns
        df[['PTM_1', 'PTM_2']] = df['binary_comb'].apply(parse_ptms).apply(pd.Series)

        # Select only the required columns for the final output
        final_columns = ['binary_comb', 'PTM_1', 'PTM_2', 'avg_interplay', 'avg_abundance_corrected_interplay', 'avg_normalized_interplay']
        final_df = df[final_columns]

        # Save to CSV
        filename = f'{condition}_{histone}_avg_interplay_scores.csv'
        final_df.to_csv(os.path.join(output_path, filename), index=False)
        print(f'Saved processed data to: {os.path.join(output_path, filename)}')

# Usage
if __name__ == "__main__":
    base_dir = os.getcwd()  # Base directory using getcwd()
    input_dir = os.path.join(base_dir, 'output', 'interplay_scores')  # Relative path to input directory
    output_dir = os.path.join(base_dir, 'output', 'interplay_scores', 'averaged_interplay_scores')  # Relative path to output directory
    annotation_path = os.path.join(base_dir, 'output', 'interplay_scores', 'experimental_annotation.csv')
    annotation_df = pd.read_csv(annotation_path)
    process_files(annotation_df, base_dir, input_dir, output_dir)
    
```