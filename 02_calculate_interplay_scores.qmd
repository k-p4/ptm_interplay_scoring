---
title: "Calculate Interplay Scores"
date: 02/13/2024
date-format: YYYY-MM-DD
author: Karl F Poncha
output: html
execute:
  echo: false
---

```{python find and match PTMs from combos_1_interplay to combos_2_interplay}
import pandas as pd
import os
import re

def parse_ptms(proteoform):
    """ Extract PTMs from the proteoform string using a regular expression. """
    ptms = re.findall(r'([A-Z]\d*[^A-Z]*)', proteoform)
    return ptms

def find_matching_files(combos_1_dir, combos_2_dir):
    """ Find matching file pairs between two directories based on file naming conventions. """
    combos_1_files = {f.replace('_combos_1.csv', ''): os.path.join(combos_1_dir, f)
                      for f in os.listdir(combos_1_dir) if f.endswith('_combos_1.csv')}
    combos_2_files = {f.replace('_combos_2.csv', ''): os.path.join(combos_2_dir, f)
                      for f in os.listdir(combos_2_dir) if f.endswith('_combos_2.csv')}

    matched_files = [(combos_1_files[k], combos_2_files[k])
                     for k in combos_1_files if k in combos_2_files]
    return matched_files

def safe_ptm_split(ptm_comb):
    """ Safely split the PTM combination string into PTM1 and PTM2, handling cases with fewer than 2 PTMs. """
    ptms = parse_ptms(ptm_comb)
    return pd.Series([ptms[0] if len(ptms) > 0 else None, ptms[1] if len(ptms) > 1 else None])

def process_files(combos_1_file, combos_2_file, output_dir):
    """ Process each file pair to merge and output the required data. """
    df1 = pd.read_csv(combos_1_file)
    df2 = pd.read_csv(combos_2_file)

    # Apply safe splitting to both DataFrames
    df2[['PTM1', 'PTM2']] = df2['PTM Combination'].apply(safe_ptm_split)
    df1[['PTM1', 'PTM2']] = df1['PTM Combination'].apply(safe_ptm_split)

    # Create lookup maps for PTM1 and PTM2 using PTM Combination as keys and Percentage Abundance as values
    abundance_lookup = df1.set_index('PTM Combination')['Percentage Abundance']

    # Use the map to replace PTM1 and PTM2 values in df2 with abundance values
    df2['PTM1_abundance'] = df2['PTM1'].map(abundance_lookup)
    df2['PTM2_abundance'] = df2['PTM2'].map(abundance_lookup)

    # Save the merged data with a new filename
    new_file_name = os.path.basename(combos_2_file).replace('_sorted_proteoform_combos_2.csv', '_interplay_scores.csv')
    output_file = os.path.join(output_dir, new_file_name)
    df2.to_csv(output_file, index=False)

base_dir = os.path.join(os.getcwd())

def main():
    """ Main function to set up directory paths and process all matched files. """
    combos_1_dir = os.path.join(base_dir, 'output', 'combos', 'combos_1_interplay')
    combos_2_dir = os.path.join(base_dir, 'output', 'combos', 'combos_2_interplay')
    output_dir = os.path.join(base_dir, 'output', 'interplay_scores')
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    matched_files = find_matching_files(combos_1_dir, combos_2_dir)
    for combos_1_file, combos_2_file in matched_files:
        process_files(combos_1_file, combos_2_file, output_dir)

if __name__ == '__main__':
    main()
```

```{python calculate interplay scores}
import pandas as pd
import numpy as np
import glob
import os

# Step 1: Define the directory and pattern for CSV files
base_dir = os.getcwd()
directory = os.path.join(base_dir, 'output', 'interplay_scores')
file_pattern = os.path.join(directory, '*_interplay_scores.csv')

# Step 2: Function to calculate new columns, optimized for pre-handling special cases
def calculate_interplay_scores_optimized(df, tolerance=1e-9):
    
    # Pre-handle special cases
    
    # Case 1: Zero Percentage Abundance
    mask1 = (df['Percentage Abundance'] == 0) & (df['PTM1_abundance'] > 0) & (df['PTM2_abundance'] > 0)
    df.loc[mask1, ['interplay', 'abundance_corrected_interplay', 'normalized_interplay']] = [-np.inf, -np.inf, -1]
    
    # Case 2: All values are 1
    mask2 = (abs(df['Percentage Abundance'] - 1) < tolerance) & \
            (abs(df['PTM1_abundance'] - 1) < tolerance) & \
            (abs(df['PTM2_abundance'] - 1) < tolerance)
    df.loc[mask2, 'normalized_interplay'] = 1
    
    # Case 3: Zero abundance for PTM1 or PTM2
    mask3 = (df['PTM1_abundance'] == 0) | (df['PTM2_abundance'] == 0)
    df.loc[mask3, ['interplay', 'abundance_corrected_interplay', 'normalized_interplay']] = np.nan
     
    # Case 4: Perfect positive crosstalk for ACI 
    mask4 = (df['Percentage Abundance'] > 0) & (df['PTM1_abundance'] > 0) & (df['PTM2_abundance'] > 0) & ((df['Percentage Abundance'] ==
    df['PTM1_abundance']) & (df['PTM1_abundance'] == df['PTM2_abundance']))
    df.loc[mask4, 'abundance_corrected_interplay'] = np.inf
    
    # Calculate remaining valid cases
    valid_mask = ~(mask1 | mask2 | mask3 | mask4)
    with np.errstate(divide='ignore', invalid='ignore'):
        df.loc[valid_mask, 'interplay'] = np.log(df.loc[valid_mask, 'Percentage Abundance'] / 
                                                 (df.loc[valid_mask, 'PTM1_abundance'] * df.loc[valid_mask, 'PTM2_abundance']))
        df.loc[valid_mask, 'abundance_corrected_interplay'] = np.log((df.loc[valid_mask, 'Percentage Abundance'] * 
                                                                      (1 - df.loc[valid_mask, 'PTM1_abundance']) * 
                                                                      (1 - df.loc[valid_mask, 'PTM2_abundance']) * 
                                                                      df.loc[valid_mask, 'Percentage Abundance']) /
                                                                     (df.loc[valid_mask, 'PTM1_abundance'] * 
                                                                      df.loc[valid_mask, 'PTM2_abundance'] * 
                                                                      (df.loc[valid_mask, 'PTM1_abundance'] - df.loc[valid_mask, 'Percentage Abundance']) * 
                                                                      (df.loc[valid_mask, 'PTM2_abundance'] - df.loc[valid_mask, 'Percentage Abundance'])))
        df.loc[valid_mask, 'normalized_interplay'] = df.loc[valid_mask, 'interplay'] / \
                                                     (-np.log(df.loc[valid_mask, 'Percentage Abundance']))
    return df

# Step 3: Process each CSV file
for file_path in glob.glob(file_pattern):
    df = pd.read_csv(file_path)
    df = calculate_interplay_scores_optimized(df)
    df.to_csv(file_path, index=False)  # Save the updated DataFrame back to CSV without the index column

print("All files have been processed and updated.")
```

```{python process files to calculate averages of interplay scores}
import os
import pandas as pd
import re

def parse_ptms(proteoform):
    ptms = re.findall(r'([A-Z]\d*[^A-Z]*)', proteoform)
    return ptms[:2]  # Only the first two PTMs

def process_files(annotation_df, base_dir, input_dir, output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    condition_histone_dfs = {}
    
    for index, row in annotation_df.iterrows():
        file_name = row['filename']
        file_path = os.path.join(input_dir, file_name)
        condition = row['condition']
        sample_name = row['sample_name']
        biorep = row['biorep']
        histone = row['histone']
        unique_suffix = f"{sample_name}_rep{biorep}_{histone}"

        try:
            data_df = pd.read_csv(file_path)
            data_df.rename(columns={'PTM Combination': 'binary_comb'}, inplace=True)
            rename_columns = {col: f'{col}_{unique_suffix}' for col in data_df.columns if col != 'binary_comb'}
            data_df.rename(columns=rename_columns, inplace=True)
            key = (condition, histone)
            if key in condition_histone_dfs:
                condition_histone_dfs[key] = pd.merge(condition_histone_dfs[key], data_df, on='binary_comb', how='outer')
            else:
                condition_histone_dfs[key] = data_df

        except FileNotFoundError:
            print(f"File not found: {file_path}")
            continue
        except Exception as e:
            print(f"Error processing file {file_name}: {e}")
            continue
    
    for (condition, histone), df in condition_histone_dfs.items():
        interplay_columns = df.filter(regex='^interplay_').columns
        df['avg_interplay'] = df[interplay_columns].mean(axis=1, skipna=True)
        
        ac_interplay_columns = df.filter(regex='^abundance_corrected_interplay_').columns
        df['avg_abundance_corrected_interplay'] = df[ac_interplay_columns].mean(axis=1, skipna=True)
        
        normalized_columns = df.filter(regex='^normalized_interplay_').columns
        df['avg_normalized_interplay'] = df[normalized_columns].mean(axis=1, skipna=True)

        df[['PTM_1', 'PTM_2']] = df['binary_comb'].apply(parse_ptms).apply(pd.Series)
        final_columns = ['binary_comb', 'PTM_1', 'PTM_2', 'avg_interplay', 'avg_abundance_corrected_interplay', 'avg_normalized_interplay']
        final_df = df[final_columns]
        filename = f'{condition}_{histone}_avg_interplay_scores.csv'
        final_df.to_csv(os.path.join(output_dir, filename), index=False)
        print(f'Saved processed data to: {os.path.join(output_dir, filename)}')

if __name__ == "__main__":
    base_dir = os.getcwd()
    input_dir = os.path.join(base_dir, 'output', 'interplay_scores')
    output_dir = os.path.join(base_dir, 'output', 'averaged_interplay_scores')
    annotation_path = os.path.join(base_dir, 'data', 'experimental_annotations', '02_interplay_averaging_experimental_annotation.csv')
    annotation_df = pd.read_csv(annotation_path)
    process_files(annotation_df, base_dir, input_dir, output_dir)

print("Interplay scores averaging completed.")


```

