---
title: "Calculate Interplay Scores"
date: 02/13/2024
date-format: YYYY-MM-DD
author: Karl F Poncha
output: html
execute:
  echo: false
---

```{python find and match PTMs from combos_1_interplay to combos_2_interplay}
import pandas as pd
import os
import re

def parse_ptms(proteoform):
    """ Extract PTMs from the proteoform string using a regular expression. """
    ptms = re.findall(r'([A-Z]\d*[^A-Z]*)', proteoform)
    return ptms

def find_matching_files(combos_1_dir, combos_2_dir):
    """ Find matching file pairs between two directories based on file naming conventions. """
    combos_1_files = {f.replace('_combos_1.csv', ''): os.path.join(combos_1_dir, f)
                      for f in os.listdir(combos_1_dir) if f.endswith('_combos_1.csv')}
    combos_2_files = {f.replace('_combos_2.csv', ''): os.path.join(combos_2_dir, f)
                      for f in os.listdir(combos_2_dir) if f.endswith('_combos_2.csv')}

    matched_files = [(combos_1_files[k], combos_2_files[k])
                     for k in combos_1_files if k in combos_2_files]
    return matched_files

def safe_ptm_split(ptm_comb):
    """ Safely split the PTM combination string into PTM1 and PTM2, handling cases with fewer than 2 PTMs. """
    ptms = parse_ptms(ptm_comb)
    return pd.Series([ptms[0] if len(ptms) > 0 else None, ptms[1] if len(ptms) > 1 else None])

def process_files(combos_1_file, combos_2_file, output_dir):
    """ Process each file pair to merge and output the required data. """
    df1 = pd.read_csv(combos_1_file)
    df2 = pd.read_csv(combos_2_file)

    # Apply safe splitting to both DataFrames
    df2[['PTM1', 'PTM2']] = df2['PTM Combination'].apply(safe_ptm_split)
    df1[['PTM1', 'PTM2']] = df1['PTM Combination'].apply(safe_ptm_split)

    # Create lookup maps for PTM1 and PTM2 using PTM Combination as keys and Percentage Abundance as values
    abundance_lookup = df1.set_index('PTM Combination')['Percentage Abundance']

    # Use the map to replace PTM1 and PTM2 values in df2 with abundance values
    df2['PTM1_abundance'] = df2['PTM1'].map(abundance_lookup)
    df2['PTM2_abundance'] = df2['PTM2'].map(abundance_lookup)

    # Save the merged data with a new filename
    new_file_name = os.path.basename(combos_2_file).replace('_sorted_proteoform_combos_2.csv', '_interplay_scores.csv')
    output_file = os.path.join(output_dir, new_file_name)
    df2.to_csv(output_file, index=False)

base_dir = os.path.join(os.getcwd())

def main():
    """ Main function to set up directory paths and process all matched files. """
    combos_1_dir = os.path.join(base_dir, 'output', 'combos', 'combos_1_interplay')
    combos_2_dir = os.path.join(base_dir, 'output', 'combos', 'combos_2_interplay')
    output_dir = os.path.join(base_dir, 'output', 'interplay_scores')
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    matched_files = find_matching_files(combos_1_dir, combos_2_dir)
    for combos_1_file, combos_2_file in matched_files:
        process_files(combos_1_file, combos_2_file, output_dir)

if __name__ == '__main__':
    main()
```

```{python}
import os
import pandas as pd
import numpy as np

def calculate_scores(df):
    try:
        # Calculate Score 1
        df['Interplay'] = np.log(df['Percentage Abundance'] / (df['PTM1_abundance'] * df['PTM2_abundance']))
        
        # Calculate Score 2
        numerator = (df['Percentage Abundance'] * (1 - df['PTM1_abundance']) * (1 - df['PTM2_abundance']) * df['Percentage Abundance'])
        denominator = (df['PTM1_abundance'] * df['PTM2_abundance'] * (df['PTM1_abundance'] - df['Percentage Abundance']) * (df['PTM2_abundance'] - df['Percentage Abundance']))
        df['Abundance_Corrected Interplay'] = np.log(numerator / denominator)
        
        # Calculate Score 3
        df['Normalized Interplay'] = df['Interplay'] / (-np.log(df['Percentage Abundance']))
    
    return df

def process_files():
    basedir = os.getcwd()  # Get the current working directory
    inputdir = os.path.join(basedir, 'output', 'interplay_scores')  # Set the target directory
    
    for root, dirs, files in os.walk(inputdir):  # Start from the input directory
        for file in files:
            if file.endswith("_interplay_scores.csv"):
                filepath = os.path.join(root, file)
                df = pd.read_csv(filepath)
                
                # Preprocess columns to avoid issues with log(0)
                df.replace(0, np.finfo(float).eps, inplace=True)
                
                # Calculate scores
                df = calculate_scores(df)
                
                # Save the updated dataframe back to the CSV
                df.to_csv(filepath, index=False)
                print(f'Processed {filepath}')

# Run the processing function
process_files()
```

```{python process files to calculate averages of interplay scores}
import os
import pandas as pd
import re

def parse_ptms(proteoform):
    # Find all post-translational modifications (PTMs) in the proteoform string
    ptms = re.findall(r'([A-Z]\d*[^A-Z]*)', proteoform)
    return ptms[:2]  # Return only the first two PTMs found

def process_files(annotation_df, base_dir, input_dir, output_dir):
    # Construct full input and output paths
    input_path = os.path.join(base_dir, input_dir)
    output_path = os.path.join(base_dir, output_dir)

    # Ensure output directory exists
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    
    # Dictionary to store dataframes for each condition and histone for processing
    condition_histone_dfs = {}

    # Loop through each file and process
    for index, row in annotation_df.iterrows():
        file_name = row['filename']
        file_path = os.path.join(input_path, file_name)
        condition = row['condition']
        sample_name = row['sample_name']
        biorep = row['biorep']
        histone = row['histone']
        unique_suffix = f"{sample_name}_rep{biorep}_{histone}"

        # Load the CSV file
        try:
            data_df = pd.read_csv(file_path)

            # Pre-rename all columns to include unique suffix, except 'binary_comb'
            rename_columns = {col: f'{col}_{unique_suffix}' for col in data_df.columns if col != 'binary_comb'}
            data_df.rename(columns=rename_columns, inplace=True)

            # Merge dataframes based on 'binary_comb', condition, and histone
            key = (condition, histone)
            if key in condition_histone_dfs:
                condition_histone_dfs[key] = pd.merge(condition_histone_dfs[key], data_df, on='binary_comb', how='outer')
            else:
                condition_histone_dfs[key] = data_df

        except FileNotFoundError:
            print(f"File not found: {file_path}")
            continue

    # Process each dataframe to fill NAs and calculate averages
    for (condition, histone), df in condition_histone_dfs.items():
        df.fillna(0, inplace=True)
        
        interplay_columns = df.filter(regex='interplay_').columns
        df['avg_interplay'] = df[interplay_columns].mean(axis=1)
        
        ac_interplay_columns = df.filter(regex='abundance_corrected_interplay_').columns
        df['avg_abundance_corrected_interplay'] = df[ac_interplay_columns].mean(axis=1)
        
        normalized_columns = df.filter(regex='normalized_interplay_').columns
        df['avg_normalized_interplay'] = df[normalized_columns].mean(axis=1)

        # Parse PTMs and add as new columns
        df[['PTM_1', 'PTM_2']] = df['binary_comb'].apply(parse_ptms).apply(pd.Series)

        # Select only the required columns for the final output
        final_columns = ['binary_comb', 'PTM_1', 'PTM_2', 'avg_interplay', 'avg_abundance_corrected_interplay', 'avg_normalized_interplay']
        final_df = df[final_columns]

        # Save to CSV
        filename = f'{condition}_{histone}_avg_interplay_scores.csv'
        final_df.to_csv(os.path.join(output_path, filename), index=False)
        print(f'Saved processed data to: {os.path.join(output_path, filename)}')

# Usage
if __name__ == "__main__":
    base_dir = os.getcwd()  # Base directory using getcwd()
    input_dir = os.path.join(base_dir, 'output', 'interplay_scores')  # Relative path to input directory
    output_dir = os.path.join(base_dir, 'output', 'averaged_interplay_scores')  # Relative path to output directory
    annotation_path = os.path.join(base_dir, 'output', 'interplay_scores', 'experimental_annotation.csv')
    annotation_df = pd.read_csv(annotation_path)
    process_files(annotation_df, base_dir, input_dir, output_dir)
    
print("Interplay scores averaging completed.")
```

